WEBVTT

1
00:00:08.923 --> 00:00:13.364
So now that we're able to retrieve
a document, HTML, text document, whatever,

2
00:00:13.364 --> 00:00:14.700
from a web server,

3
00:00:14.700 --> 00:00:17.470
now we're going to actually start sort
of sense making of the web document.

4
00:00:18.660 --> 00:00:22.784
So, here's our code, right?
This is an example of reading a web page.

5
00:00:22.784 --> 00:00:25.200
We import the urllib library.

6
00:00:25.200 --> 00:00:26.670
We open the URL.

7
00:00:26.670 --> 00:00:29.430
We read through it like a file, and

8
00:00:29.430 --> 00:00:32.900
print out,
stripping new lines at the end, right?

9
00:00:32.900 --> 00:00:36.559
And out comes the less thans and
the greater thans, that's the web page.

10
00:00:36.559 --> 00:00:39.552
And of course what the browser does,
is it looks at the h1 and

11
00:00:39.552 --> 00:00:42.502
makes the font differently and
makes it pretty on the page.

12
00:00:42.502 --> 00:00:44.428
And so there's a rendering,
what's called rendering,

13
00:00:44.428 --> 00:00:48.299
where it takes in takes that HTML,
that's in the actual return document, and

14
00:00:48.299 --> 00:00:49.954
makes it look pretty on the page.

15
00:00:49.954 --> 00:00:53.426
And that itself is a whole class
of how to make pretty web pages.

16
00:00:53.426 --> 00:00:57.570
And that's not what we're
going to talk about here.

17
00:00:57.570 --> 00:00:59.950
But basically,
when you return this information.

18
00:00:59.950 --> 00:01:03.864
If you return this information,
inside this text, and

19
00:01:03.864 --> 00:01:08.621
this is just string information at
this point in your application.

20
00:01:08.621 --> 00:01:12.600
You can look for like an anchor tag,
and the end of an anchor tag,

21
00:01:12.600 --> 00:01:16.730
and then the href attribute, and
find in these double quotes, and

22
00:01:16.730 --> 00:01:18.450
you can find another page.

23
00:01:20.000 --> 00:01:26.370
And so you can parse using regular
expressions, or find, or who knows what.

24
00:01:26.370 --> 00:01:28.836
You can parse out these things.

25
00:01:28.836 --> 00:01:34.276
And then you can,
this is exactly the string that

26
00:01:34.276 --> 00:01:39.860
you would put into that,
right, to open the URL.

27
00:01:39.860 --> 00:01:44.622
And then, if we made a loop around
this that was a bigger loop that would

28
00:01:44.622 --> 00:01:49.010
read this data, extract this string, and
do another open.

29
00:01:49.010 --> 00:01:53.330
And then read that and extract that
string and do another open, and so

30
00:01:53.330 --> 00:01:55.230
on, and so on, and so on.

31
00:01:55.230 --> 00:01:59.564
And that is how we cruise through the web.

32
00:01:59.564 --> 00:02:04.536
We put a loop around this, where we pull
the URLs out, and then we read them, and

33
00:02:04.536 --> 00:02:05.947
then we pull URL out.

34
00:02:05.947 --> 00:02:09.850
And eventually you will find your way
to pretty much everything on the Web.

35
00:02:09.850 --> 00:02:13.230
By starting at one page,
pulling all the links of that page, and

36
00:02:13.230 --> 00:02:16.380
then hitting all those links,
on and on, and on, and on.

37
00:02:16.380 --> 00:02:20.190
Your computer will probably run out of
memory before you read the whole Web.

38
00:02:20.190 --> 00:02:23.020
But that's sort of the beginning
of a Google crawler.

39
00:02:24.630 --> 00:02:28.790
And so now we're talking about sort of
how we're going to take a look at this Web

40
00:02:28.790 --> 00:02:30.250
with scraping.

41
00:02:30.250 --> 00:02:34.970
So web scraping is the term, or
web crawling, is the term that we use for

42
00:02:34.970 --> 00:02:40.070
writing applications that pretend to be
web browsers and retrieve these web pages

43
00:02:40.070 --> 00:02:43.240
and then look for the links in
those web pages and then continue.

44
00:02:43.240 --> 00:02:46.020
And it's a science all itself.

45
00:02:46.020 --> 00:02:50.455
And it's a way you can sort
of crawl the whole Web or

46
00:02:50.455 --> 00:02:54.581
make a copy of the Web or
just a piece of the Web.

47
00:02:54.581 --> 00:02:59.051
Now, what we're really doing is we're
taking that request-response cycle that I

48
00:02:59.051 --> 00:03:02.631
talked about before where you
click on something in the browser.

49
00:03:02.631 --> 00:03:05.952
Your browser sends a GET request,
the server responds with some HTML and

50
00:03:05.952 --> 00:03:08.470
then formats it up and
makes it look pretty on the page.

51
00:03:08.470 --> 00:03:11.060
You click again, round,
and around, and around.

52
00:03:11.060 --> 00:03:15.230
And instead what we're doing is we're just
kind of doing the same thing from Python.

53
00:03:15.230 --> 00:03:18.270
Doing the same thing, and
we're not clicking, we're sort of parsing.

54
00:03:18.270 --> 00:03:20.940
You parse all this stuff and

55
00:03:20.940 --> 00:03:24.300
then go to a different URL,
round, and around, and around.

56
00:03:24.300 --> 00:03:29.876
And the servers can try to do things like
put up captchas and other things to detect

57
00:03:29.876 --> 00:03:35.212
the difference between a human using
a web browser and a Python application.

58
00:03:35.212 --> 00:03:39.815
But ultimately the more sophisticated
they become to try to do

59
00:03:39.815 --> 00:03:43.545
things to fake us out or
detect and not allow this,

60
00:03:43.545 --> 00:03:46.010
then these applications
just get a little smarter.

61
00:03:46.010 --> 00:03:50.110
Now what we're going to do in this class is
we're only going to look at web pages and

62
00:03:50.110 --> 00:03:54.670
web sites that don't mind this and
some explicitly don't care, and

63
00:03:54.670 --> 00:03:55.840
some care a lot.

64
00:03:55.840 --> 00:03:58.850
So you got to be a little
careful when you do this and

65
00:03:58.850 --> 00:04:01.780
with great power comes
great responsibility, okay?

66
00:04:02.880 --> 00:04:04.223
Now why might you want to do this?

67
00:04:04.223 --> 00:04:09.125
Well, sometimes you have a system
that you don't have an API. It has has

68
00:04:09.125 --> 00:04:10.846
no export capability.

69
00:04:10.846 --> 00:04:12.146
So you write all the Python programs.

70
00:04:12.146 --> 00:04:17.000
Say okay, I'll go grab all your pages and
pull all my stuff back out.

71
00:04:17.000 --> 00:04:20.890
Sometimes you might build some,
a bit of code that checks for something.

72
00:04:20.890 --> 00:04:23.330
Like, looks for
new apartments on Craigslist.

73
00:04:23.330 --> 00:04:25.160
You could go read Craigslist web site.

74
00:04:26.830 --> 00:04:30.020
Or you could make a spider to
do your own search engine.

75
00:04:30.020 --> 00:04:32.893
Sometimes people use it
to pull social data.

76
00:04:32.893 --> 00:04:35.697
So you'll see a lot of applications
that are like Twitter applications.

77
00:04:35.697 --> 00:04:39.176
You give them permission to
look at your Twitter data, and

78
00:04:39.176 --> 00:04:41.669
off they go looking at your Twitter data.

79
00:04:41.669 --> 00:04:46.373
And so, it's a way to pull
data out when there is no

80
00:04:46.373 --> 00:04:51.301
API application programing
interface to get that.

81
00:04:51.301 --> 00:04:55.479
You got to be careful, because if everyone,
everyone taking this class,

82
00:04:55.479 --> 00:04:58.928
immediately started scraping one web page,
or one web site,

83
00:04:58.928 --> 00:05:03.330
they might get a little grumpy
because we could sort of crush them.

84
00:05:03.330 --> 00:05:06.270
They would think this would be like
a denial of service, because so

85
00:05:06.270 --> 00:05:12.260
many people are pulling web pages by
writing Python programs. It'll be bad.

86
00:05:12.260 --> 00:05:17.780
Now Facebook has some rules about this.
You can't scrape Facebook.

87
00:05:17.780 --> 00:05:25.220
Now the interesting thing about Facebook
is that, and this is a thing I grabbed.

88
00:05:25.220 --> 00:05:26.950
The interesting thing about Facebook,

89
00:05:26.950 --> 00:05:29.670
if you're not logged into to Facebook
you really can't see anything.

90
00:05:29.670 --> 00:05:30.940
There's no public data on Facebook.

91
00:05:30.940 --> 00:05:33.770
At least with Twitter there's
public data that you can see.

92
00:05:33.770 --> 00:05:36.890
But at Facebook,
you have to be logged in to see anything.

93
00:05:36.890 --> 00:05:40.940
So you can actually write a scraper for
Facebook, but you have to log

94
00:05:40.940 --> 00:05:46.360
in as yourself as the first thing your
scraper does, and then they know it's you.

95
00:05:46.360 --> 00:05:50.210
And so they're like,
oh all that logic that they put in

96
00:05:50.210 --> 00:05:53.810
to determine the difference between
when a real web browser's working and

97
00:05:53.810 --> 00:05:55.750
a piece of Python's working.

98
00:05:55.750 --> 00:05:56.430
They do that so

99
00:05:56.430 --> 00:05:59.930
they catch you doing something that
you said you weren't going to do.

100
00:05:59.930 --> 00:06:03.840
So you accepted when
you went into Facebook,

101
00:06:03.840 --> 00:06:06.930
you accepted that you're
not going to do it.

102
00:06:06.930 --> 00:06:11.700
So don't do it on Facebook,
as long as it means that like

103
00:06:11.700 --> 00:06:14.130
if you do it on Facebook then
they will blast your account and

104
00:06:14.130 --> 00:06:17.040
they'll try to make sure you
never get to use Facebook again.

105
00:06:17.040 --> 00:06:20.620
So you can sort of Google things like
Google Facebook scraping block.

106
00:06:20.620 --> 00:06:23.090
And there's all these people like,
I'm sorry.

107
00:06:23.090 --> 00:06:25.240
Please forgive me.

108
00:06:25.240 --> 00:06:26.660
Well, just don't do it.

109
00:06:26.660 --> 00:06:29.240
And you can't scrape
Google search engines.

110
00:06:29.240 --> 00:06:31.320
Because they get mad about that too.

111
00:06:31.320 --> 00:06:34.680
So you can't write your own search.

112
00:06:34.680 --> 00:06:37.580
You could technically
write a search engine.

113
00:06:37.580 --> 00:06:40.690
that took a search term and wrote
a Python program to submit the search

114
00:06:40.690 --> 00:06:43.570
term to Google, and then parsed the
results that came back from Google, and

115
00:06:43.570 --> 00:06:49.522
you could have a really awesome
search engine called Bobble, right?

116
00:06:49.522 --> 00:06:52.000
But you'd be violating
the terms of service.

117
00:06:52.000 --> 00:06:55.290
And Google copyrights their
search results, I believe, and so

118
00:06:55.290 --> 00:06:56.564
if they caught you doing that

119
00:06:56.564 --> 00:06:58.000
they'd be super grumpy.

120
00:06:59.180 --> 00:07:03.549
So, as I'm showing you all this,
be careful.

121
00:07:03.549 --> 00:07:06.069
Don't be mischievous.

122
00:07:06.069 --> 00:07:10.359
Okay, so I'm going to stop and talk about
how to parse this with a library called

123
00:07:10.359 --> 00:07:12.540
Beautiful Soup in a separate section.